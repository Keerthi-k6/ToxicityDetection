{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LSTM using GloVe"
      ],
      "metadata": {
        "id": "tBKywQeS7DOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, GlobalMaxPool1D, BatchNormalization, Dropout, Dense\n",
        "from keras.layers import Bidirectional\n",
        "from keras.models import Sequential\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import tensorflow as tf\n",
        "\n",
        "train = pd.read_csv('train1.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Assuming you have label columns for different toxic categories\n",
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# Define a function to compute the 'non_toxic' label based on absence of any toxic labels\n",
        "def compute_non_toxic(row):\n",
        "    if row[label_cols].sum() == 0:\n",
        "        return 1  # Non-toxic\n",
        "    else:\n",
        "        return 0  # Toxic\n",
        "\n",
        "# Apply the function to create the 'non_toxic' column\n",
        "train['non_toxic'] = train.apply(compute_non_toxic, axis=1)\n",
        "\n",
        "# Define label columns including 'non_toxic'\n",
        "label_cols_with_non_toxic = label_cols + ['non_toxic']\n",
        "\n",
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and strip whitespace\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning to 'comment_text' column\n",
        "train['cleaned_text'] = train['comment_text'].apply(clean_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "0yZDZ6Yf7HBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tokenizer\n",
        "tokens = Tokenizer()\n",
        "tokens.fit_on_texts(train['cleaned_text'])\n",
        "vocab_size = len(tokens.word_index) + 1\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_len = 300\n",
        "tokenized_train = tokens.texts_to_sequences(train['cleaned_text'])\n",
        "padded_train = pad_sequences(tokenized_train, maxlen=max_len, padding='post')\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "embedding_dim = 50\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "with open('glove.6B.50d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        word, *vector = line.split()\n",
        "        if word in tokens.word_index:\n",
        "            idx = tokens.word_index[word]\n",
        "            embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "# Build LSTM model with GloVe embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(LSTM(50, return_sequences = True))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(label_cols_with_non_toxic), activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define training labels including 'non_toxic'\n",
        "y_train = train[label_cols_with_non_toxic].values\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(padded_train, y_train, epochs=10, batch_size=128, validation_split=0.3)\n",
        "\n"
      ],
      "metadata": {
        "id": "rX2zKskw7Kxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(padded_train)\n",
        "y_pred = np.round(y_pred_probs)\n",
        "\n",
        "# Calculate evaluation metrics for each label including 'non_toxic'\n",
        "evaluation_metrics = {}\n",
        "for i, label in enumerate(label_cols_with_non_toxic):\n",
        "    accuracy = accuracy_score(y_train[:, i], y_pred[:, i])\n",
        "    precision = precision_score(y_train[:, i], y_pred[:, i])\n",
        "    recall = recall_score(y_train[:, i], y_pred[:, i])\n",
        "    f1 = f1_score(y_train[:, i], y_pred[:, i])\n",
        "    roc_auc = roc_auc_score(y_train[:, i], y_pred_probs[:, i])\n",
        "\n",
        "    evaluation_metrics[label] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    }\n",
        "\n",
        "# Print evaluation metrics for each label including 'non_toxic'\n",
        "for label, metrics in evaluation_metrics.items():\n",
        "    print(f\"Metrics for '{label}':\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"{metric_name}: {value}\")\n",
        "    print()\n",
        "\n",
        "# Overall classification report including 'non_toxic'\n",
        "y_true = train[label_cols_with_non_toxic].values\n",
        "y_pred_labels = np.round(y_pred_probs)\n",
        "classification_report_all = classification_report(y_true, y_pred_labels, target_names=label_cols_with_non_toxic)\n",
        "print(\"Classification Report (All Labels):\")\n",
        "print(classification_report_all)\n",
        "\n",
        "# Calculate and print average accuracy across all labels\n",
        "average_accuracy = accuracy_score(y_true, y_pred_labels)\n",
        "print(f\"Average Accuracy: {average_accuracy}\")\n"
      ],
      "metadata": {
        "id": "DQEgn4EX7WP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BILSTM using GloVe"
      ],
      "metadata": {
        "id": "3WCjzPGF7dH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tokenizer\n",
        "tokens = Tokenizer()\n",
        "tokens.fit_on_texts(train['cleaned_text'])\n",
        "vocab_size = len(tokens.word_index) + 1\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "max_len = 300\n",
        "tokenized_train = tokens.texts_to_sequences(train['cleaned_text'])\n",
        "padded_train = pad_sequences(tokenized_train, maxlen=max_len, padding='post')\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "embedding_dim = 50\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "with open('glove.6B.50d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        word, *vector = line.split()\n",
        "        if word in tokens.word_index:\n",
        "            idx = tokens.word_index[word]\n",
        "            embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "# Build LSTM model with GloVe embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(Bidirectional(LSTM(50, return_sequences = True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(label_cols_with_non_toxic), activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define training labels including 'non_toxic'\n",
        "y_train = train[label_cols_with_non_toxic].values\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(padded_train, y_train, epochs=10, batch_size=128, validation_split=0.3)\n",
        "\n"
      ],
      "metadata": {
        "id": "VCO_IHuC7fRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred_probs = model.predict(padded_train)\n",
        "y_pred = np.round(y_pred_probs)\n",
        "\n",
        "# Calculate evaluation metrics for each label including 'non_toxic'\n",
        "evaluation_metrics = {}\n",
        "for i, label in enumerate(label_cols_with_non_toxic):\n",
        "    accuracy = accuracy_score(y_train[:, i], y_pred[:, i])\n",
        "    precision = precision_score(y_train[:, i], y_pred[:, i])\n",
        "    recall = recall_score(y_train[:, i], y_pred[:, i])\n",
        "    f1 = f1_score(y_train[:, i], y_pred[:, i])\n",
        "    roc_auc = roc_auc_score(y_train[:, i], y_pred_probs[:, i])\n",
        "\n",
        "    evaluation_metrics[label] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    }\n",
        "\n",
        "# Print evaluation metrics for each label including 'non_toxic'\n",
        "for label, metrics in evaluation_metrics.items():\n",
        "    print(f\"Metrics for '{label}':\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        print(f\"{metric_name}: {value}\")\n",
        "    print()\n",
        "\n",
        "# Overall classification report including 'non_toxic'\n",
        "y_true = train[label_cols_with_non_toxic].values\n",
        "y_pred_labels = np.round(y_pred_probs)\n",
        "classification_report_all = classification_report(y_true, y_pred_labels, target_names=label_cols_with_non_toxic)\n",
        "print(\"Classification Report (All Labels):\")\n",
        "print(classification_report_all)\n",
        "\n",
        "# Calculate and print average accuracy across all labels\n",
        "average_accuracy = accuracy_score(y_true, y_pred_labels)\n",
        "print(f\"Average Accuracy: {average_accuracy}\")\n"
      ],
      "metadata": {
        "id": "M4BFVyjq7nQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tfidf - Gradient Boost"
      ],
      "metadata": {
        "id": "O2d_hWYKTm0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load train dataset\n",
        "train_df = pd.read_csv('train1.csv')\n",
        "\n",
        "# Text preprocessing function\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and strip whitespace\n",
        "    return text\n",
        "\n",
        "# Clean text data\n",
        "train_df['cleaned_text'] = train_df['comment_text'].apply(clean_text)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words=stopwords.words('english'))\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_text'])\n",
        "y_train = train_df['toxic']\n",
        "\n",
        "# Convert TF-IDF matrix to dense array\n",
        "X_train = X_train_tfidf.toarray()\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Split the balanced dataset into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_balanced, y_train_balanced, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QMDr4tzVT6nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Gradient Boosting Classifier\n",
        "gb_classifier = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_pred = gb_classifier.predict(X_val)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "\n",
        "print(\"Gradient Boosting Classifier Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "Rrz781IGT7z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM - tfidf"
      ],
      "metadata": {
        "id": "rOqApNGcUl9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load your dataset (assuming it has a 'comment_text' column and labels for toxic categories)\n",
        "train = pd.read_csv('train1.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Assuming you have label columns for different toxic categories\n",
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# Define a function to clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and strip whitespace\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning to 'comment_text' column\n",
        "train['cleaned_text'] = train['comment_text'].apply(clean_text)\n",
        "\n",
        "# Create a 'non-toxic' label based on absence of any toxic labels\n",
        "train['non_toxic'] = 1 - train[label_cols].max(axis=1)\n",
        "\n",
        "# Combine all labels (including 'non-toxic') for multi-label classification\n",
        "all_label_cols = label_cols + ['non_toxic']\n",
        "\n",
        "# Prepare TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=200, tokenizer=None, sublinear_tf=True,\n",
        "                                    min_df=1, norm='l2', encoding='utf-8', lowercase=False,\n",
        "                                    ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "# Vectorize the cleaned text data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train['cleaned_text'])\n",
        "y_train = train[all_label_cols].values\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE separately to each label column to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "y_train_resampled = np.zeros_like(y_train)\n",
        "\n",
        "for i in range(y_train.shape[1]):\n",
        "    _, y_resampled = smote.fit_resample(X_train, y_train[:, i])\n",
        "    y_train_resampled[:, i] = y_resampled[:X_train.shape[0]]  # Take only the relevant part of y_resampled\n",
        "\n",
        "# Convert sparse matrices to dense arrays for LSTM input\n",
        "X_train_dense = X_train.toarray()\n",
        "X_valid_dense = X_valid.toarray()\n",
        "\n",
        "# Reshape input data for LSTM (assuming sequences of TF-IDF vectors)\n",
        "max_len = X_train_dense.shape[1]  # Max sequence length (number of features in TF-IDF)\n",
        "X_train_lstm = X_train_dense.reshape(X_train_dense.shape[0], 1, max_len)  # Reshape for LSTM\n",
        "X_valid_lstm = X_valid_dense.reshape(X_valid_dense.shape[0], 1, max_len)  # Reshape for LSTM\n",
        "\n",
        "# Build a multi-label classification model using LSTM in Keras\n",
        "def build_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(32))\n",
        "    model.add(Dense(len(all_label_cols), activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the LSTM model\n",
        "lstm_model = build_lstm_model(input_shape=(1, max_len))\n",
        "lstm_model.fit(X_train_lstm, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_valid_lstm, y_valid), verbose=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "SyejcaDQUpxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for validation data\n",
        "y_pred_proba = lstm_model.predict(X_valid_lstm)\n",
        "y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(y_valid, y_pred_binary, target_names=all_label_cols)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracies = {}\n",
        "for i, label in enumerate(all_label_cols):\n",
        "    accuracy = accuracy_score(y_valid[:, i], y_pred_binary[:, i])\n",
        "    accuracies[label] = accuracy\n",
        "\n",
        "# Print accuracy for each label\n",
        "print(\"\\nAccuracy for Each Label:\")\n",
        "for label, acc in accuracies.items():\n",
        "    print(f\"{label}: {acc}\")\n",
        "\n",
        "# Calculate average accuracy across all labels (including 'non-toxic')\n",
        "average_accuracy = accuracy_score(y_valid, y_pred_binary, normalize=True)\n",
        "\n",
        "# Print the average accuracy\n",
        "print(\"\\nAverage Accuracy (Overall):\", average_accuracy)\n"
      ],
      "metadata": {
        "id": "mj73J27LVaHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BiLSTM - tfidf"
      ],
      "metadata": {
        "id": "tok_MC8GVkWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load your dataset (assuming it has a 'comment_text' column and labels for toxic categories)\n",
        "train = pd.read_csv('train1.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Assuming you have label columns for different toxic categories\n",
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# Define a function to clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and strip whitespace\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning to 'comment_text' column\n",
        "train['cleaned_text'] = train['comment_text'].apply(clean_text)\n",
        "\n",
        "# Create a 'non-toxic' label based on absence of any toxic labels\n",
        "train['non_toxic'] = 1 - train[label_cols].max(axis=1)\n",
        "\n",
        "# Combine all labels (including 'non-toxic') for multi-label classification\n",
        "all_label_cols = label_cols + ['non_toxic']\n",
        "\n",
        "# Prepare TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=200, tokenizer=None, sublinear_tf=True,\n",
        "                                    min_df=1, norm='l2', encoding='utf-8', lowercase=False,\n",
        "                                    ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "# Vectorize the cleaned text data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train['cleaned_text'])\n",
        "y_train = train[all_label_cols].values\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE separately to each label column to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "y_train_resampled = np.zeros_like(y_train)\n",
        "\n",
        "for i in range(y_train.shape[1]):\n",
        "    _, y_resampled = smote.fit_resample(X_train, y_train[:, i])\n",
        "    y_train_resampled[:, i] = y_resampled[:X_train.shape[0]]  # Take only the relevant part of y_resampled\n",
        "\n",
        "# Convert sparse matrices to dense arrays for BiLSTM input\n",
        "X_train_dense = X_train.toarray()\n",
        "X_valid_dense = X_valid.toarray()\n",
        "\n",
        "# Reshape input data for BiLSTM (assuming sequences of TF-IDF vectors)\n",
        "max_len = X_train_dense.shape[1]  # Max sequence length (number of features in TF-IDF)\n",
        "X_train_bilstm = X_train_dense.reshape(X_train_dense.shape[0], 1, max_len)  # Reshape for BiLSTM\n",
        "X_valid_bilstm = X_valid_dense.reshape(X_valid_dense.shape[0], 1, max_len)  # Reshape for BiLSTM\n",
        "\n",
        "# Build a multi-label classification model using Bidirectional LSTM in Keras\n",
        "def build_bilstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Bidirectional(LSTM(32)))\n",
        "    model.add(Dense(len(all_label_cols), activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the BiLSTM model\n",
        "bilstm_model = build_bilstm_model(input_shape=(1, max_len))\n",
        "bilstm_model.fit(X_train_bilstm, y_train_resampled, epochs=10, batch_size=32, validation_data=(X_valid_bilstm, y_valid), verbose=1)\n",
        "\n",
        "# Generate predictions for validation data\n",
        "y_pred_proba = bilstm_model.predict(X_valid_bilstm)\n",
        "y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(y_valid, y_pred_binary, target_names=all_label_cols)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "# Calculate accuracy for each label\n",
        "accuracies = {}\n",
        "for i, label in enumerate(all_label_cols):\n",
        "    accuracy = accuracy_score(y_valid[:, i], y_pred_binary[:, i])\n",
        "    accuracies[label] = accuracy\n",
        "\n",
        "# Print accuracy for each label\n",
        "print(\"\\nAccuracy for Each Label:\")\n",
        "for label, acc in accuracies.items():\n",
        "    print(f\"{label}: {acc}\")\n",
        "\n",
        "# Calculate average accuracy across all labels (including 'non-toxic')\n",
        "average_accuracy = accuracy_score(y_valid, y_pred_binary, normalize=True)\n",
        "\n",
        "# Print the average accuracy\n",
        "print(\"\\nAverage Accuracy (Overall):\", average_accuracy)\n"
      ],
      "metadata": {
        "id": "TpUbYeHIViLs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
